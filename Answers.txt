Вопрос 1:
Почему использование методов машинного обучения оправдано в этой задаче? 
Как бы Вы ее решали без их использования? 

С таким объемом данных, полученных в достаточно новой области вручную работать уже невозможно. Теоретических знаний для точного решения у человечества тоже пока недостает (да и не факт, что такие задачи вообще можно решить точно). Машинное обучение как раз позволяет, среди всего прочего, находить зависимости используя большие наборы данных, чем мы здесь и воспользовались.
В отсутствии машинного обучения я привлек бы статистические методы, например, построил бы логистическую регрессию. Хотя, в целом, методы машинного обучения достаточно сильно пересекаются с статистическим матаппаратом.
Или же подошел бы к задаче как физик, а не как математик - возможно, из знаний о физике процессов можно извлечь что-то полезное, что помогло бы решить данную задачу.

Вопрос 2:
Как Вы её решали и почему так? Что пробовали использовать? 

Сразу сделал выбор в пользу композиции слабых моделей. Недавно работал с Random Forest и мне показалось, что он хорошо себя покажет в этой задаче. Затем вспомнил, что градинентный бустинг сейчас очень популярен, погуглил, решил перейти к нему. В итоге выбор пал на использование XGBoost. Судя по отзывам, он дает лучший результат, чем его аналог из sklearn и, вдобавок, нативно поддерживает NA значения. В предыдущих задачах я ни с тем, ни с другим не работал (вообще, я больше занимаюсь прогнозированием временных рядов).
Кстати, мне кажется, Yandex Matrix Net как раз-таки использует градиентный бустинг над решающим деревьями.
Если кратко, эволюция решения выглядит следующим образом: RandomForestClassifier -> GradientBoostingClassifier (оба из sklearn) -> XGBoost

Вопрос 3:
Насколько хорошо себя ведёт ваша модель и как Вы это оценивали? 

Помимо заданной метрики качества смотрел на число ошибок на классификции. Подбор параметров - с помощью кросс-валидации на разбиениях обучабщей выборки на подвыборки.

Вопрос 4:
Как нужно выбирать порог классификации для оптимизации метрики качества?

Для оптимизации AMS можно использовать ROC-кривую чтобы посмотреть на количество ошибок при классификации. Учитывая, что у объектов есть веса, можно использовать WTPR и WFPR (weighted true and false positive rates). Согласно данной статье (http://jmlr.org/proceedings/papers/v42/diaz14.pdf), оптимальным порогом является значение AMS между 0.14 и 0.16. В моей работе было выбрано значение 0.15.